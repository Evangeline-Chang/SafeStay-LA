{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import string\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_after2020 = pd.read_csv('data/reviews_2020_check.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1270"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_after2020['comments'] = review_after2020['comments'].str.strip()\n",
    "review_after2020 = review_after2020[review_after2020['comments'] != '']\n",
    "\n",
    "# drop na\n",
    "review_after2020.dropna(inplace=True)\n",
    "\n",
    "# remove the rows with less than 5 characters\n",
    "mask = review_after2020['comments'].str.len() >= 5\n",
    "review_after2020 = review_after2020[mask]\n",
    "\n",
    "review_after2020.reset_index(drop=True, inplace=True)\n",
    "len(review_after2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1270/1270 [00:00<00:00, 2826.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1249"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random non-english words from languages that also uses the latin script\n",
    "# remove those rows not written in English\n",
    "non_english_words = [re.compile(r'\\bestancia\\b', re.IGNORECASE), re.compile(r'\\bzgodne\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\buma\\b', re.IGNORECASE), re.compile(r'\\bEspao\\b', re.IGNORECASE), re.compile(r'\\bett\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\boleskelu\\b', re.IGNORECASE), re.compile(r'\\bmuy\\b', re.IGNORECASE), re.compile(r'\\bflott\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bbairro\\b', re.IGNORECASE), re.compile(r'\\bOrt\\b', re.IGNORECASE), re.compile(r'\\bpiacere\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\banfitrión\\b', re.IGNORECASE), re.compile(r'\\berittäin\\b', re.IGNORECASE), re.compile(r'\\blugar\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bendroit\\b', re.IGNORECASE), re.compile(r'\\bHaus\\b', re.IGNORECASE), \n",
    "    re.compile(r'\\bEstadia\\b', re.IGNORECASE), re.compile(r'\\bvecindario\\b', re.IGNORECASE), re.compile(r'\\bGroßartig\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bEstuvimos\\b', re.IGNORECASE), re.compile(r'\\bisäntä\\b', re.IGNORECASE),  re.compile(r'\\bdet\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bEstdio\\b', re.IGNORECASE), re.compile(r'\\bmycket\\b', re.IGNORECASE), re.compile(r'\\bum\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bestaba\\b', re.IGNORECASE), re.compile(r'\\blocalização\\b', re.IGNORECASE), re.compile(r'\\bes\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bophold\\b', re.IGNORECASE), re.compile(r'\\bamfitriona\\b', re.IGNORECASE), re.compile(r'\\bgeweldig\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bein\\b', re.IGNORECASE), re.compile(r'\\bduda\\b', re.IGNORECASE), re.compile(r'\\buna\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\blimpio\\b', re.IGNORECASE), re.compile(r'\\bbueno\\b', re.IGNORECASE), re.compile(r'\\bgastheer\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bsted\\b', re.IGNORECASE), re.compile(r'\\bottimo\\b', re.IGNORECASE), re.compile(r'\\bgastvrouw\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bposizione\\b', re.IGNORECASE), re.compile(r'\\bet\\b', re.IGNORECASE), re.compile(r'\\bnaapurusto\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bséjour\\b', re.IGNORECASE), re.compile(r'\\baimer\\b', re.IGNORECASE), re.compile(r'\\bgénial\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bgrozav\\b', re.IGNORECASE), re.compile(r'\\bfoarte\\b', re.IGNORECASE), re.compile(r'\\bvert\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\btycka\\b', re.IGNORECASE), re.compile(r'\\bestadia\\b', re.IGNORECASE), re.compile(r'\\been\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bamfitrió\\b', re.IGNORECASE), re.compile(r'\\bgazdă\\b', re.IGNORECASE), re.compile(r'\\bEst\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bfoi\\b', re.IGNORECASE), re.compile(r'\\bEspacio\\b', re.IGNORECASE), re.compile(r'\\blide\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bbuen\\b', re.IGNORECASE), re.compile(r'\\bmahtava\\b', re.IGNORECASE), re.compile(r'\\bplăcea\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bnabolag\\b', re.IGNORECASE), re.compile(r'\\bAufenthalt\\b', re.IGNORECASE), re.compile(r'\\bden\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bplacering\\b', re.IGNORECASE), re.compile(r'\\btrès\\b', re.IGNORECASE), re.compile(r'\\bel\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bubicación\\b', re.IGNORECASE), re.compile(r'\\bluogo\\b', re.IGNORECASE), re.compile(r'\\bquartier\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bloc\\b', re.IGNORECASE), re.compile(r'\\bvärd\\b', re.IGNORECASE), re.compile(r'\\bLage\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bhyvä\\b', re.IGNORECASE), re.compile(r'\\bgracias\\b', re.IGNORECASE), re.compile(r'\\bsoggiorno\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bmolto\\b', re.IGNORECASE), re.compile(r'\\bbarri\\b', re.IGNORECASE), re.compile(r'\\bverblijf\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bplaats\\b', re.IGNORECASE), re.compile(r'\\bEstuvo\\b', re.IGNORECASE), re.compile(r'\\bagradar\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bótimo\\b', re.IGNORECASE), re.compile(r'\\bestada\\b', re.IGNORECASE), re.compile(r'\\bgrannskap\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bsijainti\\b', re.IGNORECASE), re.compile(r'\\bmeget\\b', re.IGNORECASE), re.compile(r'\\banfitrião\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bGastgeber\\b', re.IGNORECASE), re.compile(r'\\bmaison\\b', re.IGNORECASE), re.compile(r'\\bfantastisk\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bkan\\b', re.IGNORECASE), re.compile(r'\\bospite\\b', re.IGNORECASE), re.compile(r'\\blocație\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bveldig\\b', re.IGNORECASE), re.compile(r'\\bom\\b', re.IGNORECASE), re.compile(r'\\bmuito\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bbé\\b', re.IGNORECASE), re.compile(r'\\blloc\\b', re.IGNORECASE), re.compile(r'\\bleuk\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bsehr\\b', re.IGNORECASE), re.compile(r'\\bbian\\b', re.IGNORECASE), re.compile(r'\\bhet\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\ble\\b', re.IGNORECASE), re.compile(r'\\berg\\b', re.IGNORECASE), re.compile(r'\\bder\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bpitää\\b', re.IGNORECASE), re.compile(r'\\bo\\b', re.IGNORECASE), re.compile(r'\\bEstancia\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bmolt\\b', re.IGNORECASE), re.compile(r'\\bcea\\b', re.IGNORECASE), re.compile(r'\\bhuis\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bund\\b', re.IGNORECASE), re.compile(r'\\bplass\\b', re.IGNORECASE), re.compile(r'\\bEsta\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bopphold\\b', re.IGNORECASE), re.compile(r'\\bmit\\b', re.IGNORECASE), re.compile(r'\\bGut\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bgoed\\b', re.IGNORECASE), re.compile(r'\\bubicació\\b', re.IGNORECASE), re.compile(r'\\beine\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bbuono\\b', re.IGNORECASE), re.compile(r'\\bNachbarschaft\\b', re.IGNORECASE), re.compile(r'\\bcasă\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bMögen\\b', re.IGNORECASE), re.compile(r'\\bil\\b', re.IGNORECASE), re.compile(r'\\bbon\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bgostar\\b', re.IGNORECASE), re.compile(r'\\bemäntä\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bbra\\b', re.IGNORECASE), re.compile(r'\\bdas\\b', re.IGNORECASE), re.compile(r'\\blocatie\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bhôte\\b', re.IGNORECASE), re.compile(r'\\bvinden\\b', re.IGNORECASE), re.compile(r'\\bEste\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bemplacement\\b', re.IGNORECASE), re.compile(r'\\bgenial\\b', re.IGNORECASE), re.compile(r'\\bvært\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bquartiere\\b', re.IGNORECASE), re.compile(r'\\bde\\b', re.IGNORECASE), re.compile(r'\\bbom\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bune\\b', re.IGNORECASE), re.compile(r'\\bședere\\b', re.IGNORECASE), re.compile(r'\\bplats\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bvistelse\\b', re.IGNORECASE), re.compile(r'\\bpaikka\\b', re.IGNORECASE), re.compile(r'\\bgustar\\b', re.IGNORECASE),\n",
    "    re.compile(r'\\bbuurt\\b', re.IGNORECASE), re.compile(r'\\btalo\\b', re.IGNORECASE), re.compile(r'\\bhus\\b', re.IGNORECASE)]\n",
    "\n",
    "def contains_non_english(text):\n",
    "    for pattern in non_english_words:\n",
    "        if pattern.search(text):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "tqdm.pandas()\n",
    "review_after2020['Contains_Non_English'] = review_after2020['comments'].progress_apply(contains_non_english)\n",
    "review_after2020 = review_after2020[~review_after2020['Contains_Non_English']]\n",
    "review_after2020.drop(columns=['Contains_Non_English'], inplace=True)\n",
    "# review_after2020_eng = review_after2020\n",
    "len(review_after2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1249/1249 [00:00<00:00, 110343.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# remove <br/> and apostrophes\n",
    "def empty_lines_apostrophes(text):\n",
    "    text = text.replace('<br/>', '')\n",
    "    text = text.replace(\"‘\", \"'\").replace(\"’\", \"'\").replace(\"'s\", '').replace(\"'ll\", ' will').replace(\"'m\", ' am').replace(\"'re\", ' are').replace(\"n't\", ' not').replace(\"'ve\", ' have').replace(\"Ive\", 'I have')\n",
    "    text = text.replace(\"you'd\", 'you would').replace('youll', 'you will').replace('youre', 'you are').replace('youd', 'you would').replace('Youll', 'You will').replace('Youre', 'You are').replace('Youd', 'You would')\n",
    "    return text\n",
    "\n",
    "tqdm.pandas()\n",
    "review_after2020['comments'] = review_after2020['comments'].progress_apply(empty_lines_apostrophes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1249/1249 [00:00<00:00, 145636.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# remove non-English characters from comments\n",
    "def english_only(text):\n",
    "    text = str(text)\n",
    "    text = text.replace('&', 'and')\n",
    "    text = re.sub(r'[^0-9A-Za-z;,:.?! ]+', '', text)\n",
    "    return text\n",
    "\n",
    "tqdm.pandas()\n",
    "review_after2020['comments'] = review_after2020['comments'].progress_apply(english_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1249/1249 [00:00<00:00, 113662.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# replace two or more consecutive punctuations\n",
    "def remove_multiple_punc(text):\n",
    "    return re.sub(r'[;,:.?! ]{3,}', '.', text)\n",
    "\n",
    "tqdm.pandas()\n",
    "review_after2020['comments'] = review_after2020['comments'].progress_apply(remove_multiple_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1249/1249 [00:00<00:00, 571098.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# if first character is a punctuation, remove it\n",
    "def remove_punctuation_if_first_char_punctuation(text):\n",
    "    if text and text[0] in string.punctuation:\n",
    "        return text[1:].strip(string.punctuation)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "tqdm.pandas()\n",
    "review_after2020['comments'] = review_after2020['comments'].progress_apply(remove_punctuation_if_first_char_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1249/1249 [00:00<00:00, 48095.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1128"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the rows if there are less than 20 letters if punctuations were removed\n",
    "def count_english_letters(text):\n",
    "    english_letters = re.findall(r'[a-zA-Z]', text)\n",
    "    return len(english_letters)\n",
    "\n",
    "tqdm.pandas()\n",
    "review_after2020 = review_after2020[review_after2020['comments'].progress_apply(lambda x: count_english_letters(x)) >= 20]\n",
    "len(review_after2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1128/1128 [00:00<00:00, 56396.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# add space after punctuation (if none) and remove extra spaces\n",
    "def spaces_before_after_punctuation(text):\n",
    "    text = re.sub(r'\\s+([.,:;!?])', r'\\1', text)\n",
    "    text = re.sub(r'(?<=[.,;:!?])(?![ ])', ' ', text)\n",
    "    return text\n",
    "\n",
    "tqdm.pandas()\n",
    "review_after2020['comments'] = review_after2020['comments'].progress_apply(spaces_before_after_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1128/1128 [00:00<00:00, 501981.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# add period to the end of each comment (if none) in order to join them together\n",
    "def add_period_to_comments(text):\n",
    "    text = text.strip()\n",
    "    if text[-1] not in string.punctuation:\n",
    "        return text + '.'\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "tqdm.pandas()\n",
    "review_after2020['comments'] = review_after2020['comments'].progress_apply(add_period_to_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1128"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove unusable rows\n",
    "review_after2020['comments'] = review_after2020['comments'].str.strip()\n",
    "review_after2020 = review_after2020[review_after2020['comments'] != '']\n",
    "\n",
    "mask = review_after2020['comments'].str.len() >= 5\n",
    "review_after2020 = review_after2020[mask]\n",
    "\n",
    "review_after2020 = review_after2020[review_after2020['comments'].str.contains(' ')]\n",
    "\n",
    "review_after2020.reset_index(drop=True, inplace=True)\n",
    "\n",
    "len(review_after2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39471761</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22215734</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23395506</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id  review_count\n",
       "2    39471761           536\n",
       "0    22215734           520\n",
       "1    23395506            72"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_count = review_after2020.groupby(['listing_id']).size().reset_index(name='review_count').sort_values(by=['review_count'], ascending=False)\n",
    "reviews_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# filter those listings with more than 15 reviews\n",
    "# After trying so many times, I think it needs at least 15 reviews for the model to run well\n",
    "review_counts_15 = reviews_count[reviews_count['review_count'] >= 15]\n",
    "print(len(review_counts_15))\n",
    "count_15_ids = review_counts_15['listing_id'].unique()\n",
    "review_after2020_15 = review_after2020[review_after2020['listing_id'].isin(count_15_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 3/3 [00:01<00:00,  2.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# first join commenets then run the keyword extraction model\n",
    "grouped = review_after2020_15.groupby('listing_id')['comments'].apply(lambda x: \" \".join(x)).reset_index()\n",
    "grouped['comments'] = grouped['comments'].apply(lambda x: x.lower())\n",
    "\n",
    "grouped['keywords_ori'] = None\n",
    "\n",
    "kw_extractor = yake.KeywordExtractor()\n",
    "\n",
    "tqdm.pandas()\n",
    "for index, row in tqdm(grouped.iterrows(), total=len(grouped), desc=\"Processing rows\"):\n",
    "    text = row['comments']\n",
    "\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    keyword_list = [word_tuple[0] for word_tuple in keywords]\n",
    "    grouped.at[index, 'keywords_ori'] = keyword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set words that contains little information, will remove them in the next cell\n",
    "\n",
    "# the whole phrase will be removed if contains these words\n",
    "more = ['Airbnb', 'airbnb',  'bnb', 'BNB', 'B&B', 'b&b', 'abandb', 'air bnb', 'ass', 'who', 'what', 'lol', \n",
    "        'buy', 'sooo', 'years in socal', 'dope', '20-30 minutes', 'write another glowing', 'need-a full size', \n",
    "        'boyfriend flight', 'brothers stayed', 'couple of hiccups', 'blisko', '5-10 minutes', 'minutes', 'due', \n",
    "        'drop my', 'drop off', 'los', 'tagthe']\n",
    "\n",
    "# these words alone basically have no meaning, they can only exist with other words\n",
    "# great location (OK), location (NOT OK)\n",
    "single = ['site', 'website','wife', 'husband', 'absolutely', 'really', 'proximity', 'probably', 'definitely',\n",
    "          'angeles', 'alley', 'back', 'night', 'side', 'host', 'time', 'people','street', 'unit', 'gonna', 'need', \n",
    "          'boyfriend', 'girlfriend', 'also', 'felt', 'listing', 'listings', 'listed', 'advertised', 'another', 'daughter',\n",
    "          'away', 'coming', 'person', 'la', 'los', 'made', 'brand', 'could', 'wooow', 'didnt', 'staff', 'yortoise', \n",
    "          'guesthouse', 'guest', 'views', 'home', 'boat', 'neighborhood', 'needed', 'inn', 'hotel', 'address',\n",
    "          'stay', 'place', 'would', 'area', 'spot', 'location', 'space', 'apartment', 'house', 'room','ocean', \n",
    "          'boyfriend', 'brother', 'lot', 'lots', 'lynsey', 'madre', 'make', 'year', 'rooms']\n",
    "\n",
    "# some names that I gather from all places, needed to be removed\n",
    "common_name = pd.read_csv('data/more_names.csv')\n",
    "common_name['Names'] = common_name['Names'].str.strip()\n",
    "common_names = list(set(common_name['Names'].tolist()))\n",
    "common_names = [name.lower() for name in common_names]\n",
    "\n",
    "more_names = ['zhenya', 'moira', 'gwen', 'abbot', 'kinney', 'zevarra', 'wolford', 'chia', 'chia mei',\n",
    "              'ingy', 'iganacia', 'sora', 'iry', 'havette', 'heath', 'amberr', 'rochelle', 'nellie', 'evy', 'eryn']\n",
    "\n",
    "# host names, needed to be removed\n",
    "def abc_only(text):\n",
    "    text = str(text)\n",
    "    text = text.replace('&', 'and')\n",
    "    text = re.sub(r'[^A-Za-z ]+', '', text)\n",
    "    return text\n",
    "listings = pd.read_csv('data/listings_check.csv', index_col=0)\n",
    "listings['host_name'] = listings['host_name'].apply(abc_only)\n",
    "host_name = listings['host_name'].tolist()\n",
    "host_name = [name.strip().lower() for name in host_name if isinstance(name, str) and len(name) > 2]\n",
    "host_name = list(set(host_name))\n",
    "\n",
    "host_names = host_name\n",
    "for item in host_name:\n",
    "    if ' ' in item:\n",
    "        split_words = item.split(' ')\n",
    "        for split in split_words:\n",
    "            if (len(split) > 2) and (split != 'and'):\n",
    "                host_names.append(split)\n",
    "host_names = [word for word in host_names if (word != 'and') and (word != '') and (len(str(word)) > 2) and (word != 'beach')]\n",
    "host_names = list(set(host_names))\n",
    "\n",
    "all_names = list(set(common_names + host_names))\n",
    "all_names.extend(more_names)\n",
    "all_names_s = [name + 's' if not name.endswith('s') else name for name in all_names]\n",
    "all_names = all_names + all_names_s\n",
    "# added space so that phrases like 'wendy's cottage' can be removed\n",
    "all_names_space = [name + ' ' for name in all_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 3/3 [00:00<00:00, 362.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# remove meaningless words / phrases\n",
    "grouped['keywords_filtered'] = None\n",
    "\n",
    "tqdm.pandas()\n",
    "for index, row in tqdm(grouped.iterrows(), total=len(grouped), desc=\"Processing rows\"):\n",
    "    keyword_list = row['keywords_ori']\n",
    "    filtered_keyword = []\n",
    "    \n",
    "    for word in keyword_list:\n",
    "        if (\n",
    "            (word not in single) and \n",
    "            (word not in all_names) and \n",
    "            (word not in more) and \n",
    "            (all(text not in word for text in more)) and\n",
    "            (all(text not in word for text in all_names_space)) and\n",
    "            ('s place' not in word) and ('s home' not in word) and \n",
    "            ('. ' not in word)\n",
    "        ):\n",
    "            filtered_keyword.append(word)\n",
    "            grouped.at[index, 'keywords_filtered'] = filtered_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top seven keywords of each listing\n",
    "def top7(list):\n",
    "    if list != None:\n",
    "        return list[0:7]\n",
    "\n",
    "grouped['top7'] = grouped['keywords_filtered'].apply(top7)\n",
    "\n",
    "grouped['one'] = grouped['top7'].apply(lambda x: x[0] if x else None)\n",
    "grouped['two'] = grouped['top7'].apply(lambda x: x[1] if x != None and len(x) > 1 else None)\n",
    "grouped['three'] = grouped['top7'].apply(lambda x: x[2] if x != None and len(x) > 2 else None)\n",
    "grouped['four'] = grouped['top7'].apply(lambda x: x[3] if x != None and len(x) > 3 else None)\n",
    "grouped['five'] = grouped['top7'].apply(lambda x: x[4] if x != None and len(x) > 4 else None)\n",
    "grouped['six'] = grouped['top7'].apply(lambda x: x[5] if x != None and len(x) > 5 else None)\n",
    "grouped['seven'] = grouped['top7'].apply(lambda x: x[6] if x != None and len(x) > 6 else None)\n",
    "\n",
    "grouped['one'] = grouped['one'].apply(lambda x: x + ', ' if x != None else None)\n",
    "grouped['two'] = grouped['two'].apply(lambda x: x + ', ' if x != None else None)\n",
    "grouped['three'] = grouped['three'].apply(lambda x: x + ', ' if x != None else None)\n",
    "grouped['four'] = grouped['four'].apply(lambda x: x + ', ' if x != None else None)\n",
    "grouped['five'] = grouped['five'].apply(lambda x: x + ', ' if x != None else None)\n",
    "grouped['six'] = grouped['six'].apply(lambda x: x + ', ' if x != None else None)\n",
    "\n",
    "# add another column; if safe is one of the keywords but not in top7, mark it\n",
    "grouped['safe'] = None\n",
    "grouped['safe'] = grouped.apply(lambda row: ', safe' if 'safe' in row['keywords_filtered'] and 'safe' not in row['top7'] else None, axis=1)\n",
    "\n",
    "grouped = grouped.drop('top7', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# this column will be used on visualization\n",
    "grouped['safe_all'] = None\n",
    "grouped['safe_all'] = grouped.apply(lambda row: 'Safe' if 'safe' in row['keywords_filtered'] else None, axis=1)\n",
    "print(len(grouped[grouped['safe_all'] == 'Safe']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.to_csv('data/keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join keywords df with the original df\n",
    "listing_keywords_joined = pd.merge(listings, grouped, left_on='id', right_on='listing_id', how='left')\n",
    "\n",
    "# this column will be used on the tooltip of the map\n",
    "listing_keywords_joined['keywords_title'] = ''\n",
    "listing_keywords_joined.loc[listing_keywords_joined['keywords_filtered'].notna(), 'keywords_title'] = 'Top keywords of Comments: '\n",
    "\n",
    "# remove rows with accommodates == 0\n",
    "listing_keywords_joined = listing_keywords_joined[listing_keywords_joined['accommodates'] != 0]\n",
    "\n",
    "# fill NaN reviews with 0\n",
    "columns_to_replace = [col for col in listing_keywords_joined.columns if col.startswith('review')]\n",
    "listing_keywords_joined[columns_to_replace] = listing_keywords_joined[columns_to_replace].fillna(0)\n",
    "\n",
    "listing_keywords_joined.drop(columns=['listing_id', 'comments', 'keywords_ori', 'keywords_filtered'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>...</th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "      <th>four</th>\n",
       "      <th>five</th>\n",
       "      <th>six</th>\n",
       "      <th>seven</th>\n",
       "      <th>safe</th>\n",
       "      <th>safe_all</th>\n",
       "      <th>keywords_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22215734</td>\n",
       "      <td>https://www.airbnb.com/rooms/22215734</td>\n",
       "      <td>Guest suite in Culver City · ★4.94 · Studio · ...</td>\n",
       "      <td>162330741</td>\n",
       "      <td>Isaac</td>\n",
       "      <td>33.98326</td>\n",
       "      <td>-118.38873</td>\n",
       "      <td>Entire guest suite</td>\n",
       "      <td>Entire Home/Apartment</td>\n",
       "      <td>$119.00</td>\n",
       "      <td>...</td>\n",
       "      <td>great,</td>\n",
       "      <td>great place,</td>\n",
       "      <td>clean,</td>\n",
       "      <td>great stay,</td>\n",
       "      <td>great location,</td>\n",
       "      <td>easy,</td>\n",
       "      <td>nice</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Top keywords of Comments:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23395506</td>\n",
       "      <td>https://www.airbnb.com/rooms/23395506</td>\n",
       "      <td>Guest suite in Los Angeles · ★4.99 · 1 bedroom...</td>\n",
       "      <td>174427526</td>\n",
       "      <td>Jeff and Shelley</td>\n",
       "      <td>34.04528</td>\n",
       "      <td>-118.42078</td>\n",
       "      <td>Entire guest suite</td>\n",
       "      <td>Entire Home/Apartment</td>\n",
       "      <td>$119.00</td>\n",
       "      <td>...</td>\n",
       "      <td>hosts,</td>\n",
       "      <td>great,</td>\n",
       "      <td>beautiful,</td>\n",
       "      <td>garden,</td>\n",
       "      <td>great place,</td>\n",
       "      <td>loved,</td>\n",
       "      <td>amazing</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Top keywords of Comments:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39471761</td>\n",
       "      <td>https://www.airbnb.com/rooms/39471761</td>\n",
       "      <td>Guest suite in Hawthorne · ★4.93 · Studio · 1 ...</td>\n",
       "      <td>153462014</td>\n",
       "      <td>Grant</td>\n",
       "      <td>33.92186</td>\n",
       "      <td>-118.36916</td>\n",
       "      <td>Entire guest suite</td>\n",
       "      <td>Entire Home/Apartment</td>\n",
       "      <td>$142.00</td>\n",
       "      <td>...</td>\n",
       "      <td>great place,</td>\n",
       "      <td>great,</td>\n",
       "      <td>clean,</td>\n",
       "      <td>great stay,</td>\n",
       "      <td>great location,</td>\n",
       "      <td>nice,</td>\n",
       "      <td>nice place</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Top keywords of Comments:</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                            listing_url  \\\n",
       "0  22215734  https://www.airbnb.com/rooms/22215734   \n",
       "1  23395506  https://www.airbnb.com/rooms/23395506   \n",
       "2  39471761  https://www.airbnb.com/rooms/39471761   \n",
       "\n",
       "                                                name    host_id  \\\n",
       "0  Guest suite in Culver City · ★4.94 · Studio · ...  162330741   \n",
       "1  Guest suite in Los Angeles · ★4.99 · 1 bedroom...  174427526   \n",
       "2  Guest suite in Hawthorne · ★4.93 · Studio · 1 ...  153462014   \n",
       "\n",
       "          host_name  latitude  longitude       property_type  \\\n",
       "0             Isaac  33.98326 -118.38873  Entire guest suite   \n",
       "1  Jeff and Shelley  34.04528 -118.42078  Entire guest suite   \n",
       "2             Grant  33.92186 -118.36916  Entire guest suite   \n",
       "\n",
       "               room_type    price  ...            one            two  \\\n",
       "0  Entire Home/Apartment  $119.00  ...        great,   great place,    \n",
       "1  Entire Home/Apartment  $119.00  ...        hosts,         great,    \n",
       "2  Entire Home/Apartment  $142.00  ...  great place,         great,    \n",
       "\n",
       "         three          four              five      six       seven  safe  \\\n",
       "0      clean,   great stay,   great location,    easy,         nice  None   \n",
       "1  beautiful,       garden,      great place,   loved,      amazing  None   \n",
       "2      clean,   great stay,   great location,    nice,   nice place  None   \n",
       "\n",
       "  safe_all              keywords_title  \n",
       "0     None  Top keywords of Comments:   \n",
       "1     None  Top keywords of Comments:   \n",
       "2     None  Top keywords of Comments:   \n",
       "\n",
       "[3 rows x 32 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_keywords_joined.to_csv('data/Airbnb_keywords.csv')\n",
    "listing_keywords_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
